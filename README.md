# ğŸ¤–llm-log

> Still WIP. Be careful of breaking changes.

## ğŸ“„Introduction

We want to apply LLM to anomaly detection in logs.

## ğŸ“‡Project Structure

```
.
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ dataset
â”‚         â””â”€â”€ ...
â”œâ”€â”€ misc
â”‚         â””â”€â”€ ...
â”œâ”€â”€ models
â”‚         â”œâ”€â”€ phi-4-Q6_K.gguf
â”‚         â””â”€â”€ ...
â””â”€â”€ src
    â”œâ”€â”€ chroma_db
    â”‚         â””â”€â”€ ...
    â”œâ”€â”€ configs
    â”‚         â”œâ”€â”€ config_phi-4_BGL_test.toml
    â”‚         â”œâ”€â”€ config_phi-4_liberty2_test.toml
    â”‚         â””â”€â”€ ...
    â”œâ”€â”€ rag_dataset
    â”‚         â”œâ”€â”€ phi-4_BGL_test.txt
    â”‚         â”œâ”€â”€ phi-4_liberty2_test.txt
    â”‚         â””â”€â”€ ...
    â”œâ”€â”€ results
    â”‚         â”œâ”€â”€ extracted_dataset.txt
    â”‚         â”œâ”€â”€ line_num.txt
    â”‚         â””â”€â”€ output.txt
    â”œâ”€â”€ main.py
    â”œâ”€â”€ model.py
    â”œâ”€â”€ my_utils.py
    â””â”€â”€ vector_database.py
```

## âš™ï¸Config Example

```toml
[debug]
verbose = false

[model]
model_path = "path/to/model.gguf"
num_max_content_tokens = 8192
num_gpu_layers = 41
num_buffer_size = 1
prompt_without_rag = """..."""
prompt_with_rag = """..."""

[rag]
chroma_db_dir = "chroma_db"
collection_name = "documents"

[dataset]
dataset_name = "liberty2/BGL/Thunderbird"
dataset_path = "path/to/dataset"
```

